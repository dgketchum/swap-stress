import os
import time
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from lmfit import Model
import pymc as pm
import pytensor.tensor as pt


class SWRC:
    """
    A class to encapsulate Soil Water Retention Curve (SWRC) data,
    fit the van Genuchten-Mualem model for one or more depths/groups,
    and visualize the results.

    Input data options:
      - Provide a file path (CSV or Parquet) with either:
          ('KPA','VWC') columns or ('suction_cm','theta') columns, and a depth column
      - Provide a pandas DataFrame via `df` having required columns:
          'suction' (head/psi in cm), 'theta' (VWC), and 'depth' (cm)

    Notes:
      - psi/head and depth units are centimeters (cm)

    Reference:
    Memari, S.S. and Clement, T.P., 2021. PySWR-A Python code for fitting soil water
    retention functions. Computers & Geosciences, 156, p.104897.

    """

    def __init__(self, filepath=None, depth_col=None, df=None):
        """
        Initialize the SWRC fitter from a file or a DataFrame.

        Args:
            filepath (str, optional): Path to a CSV or Parquet file.
            depth_col (str, optional): Column to group by; defaults to 'depth' for DataFrame input
                                       and 'stationDepth [cm]' for file input if present.
            df (pandas.DataFrame, optional): DataFrame with columns 'suction' [cm], 'theta', 'depth' [cm].
        """
        self.filepath = filepath
        self.data_by_depth = {}
        self.fit_results = {}
        self.metadata = {}
        self._vg_model = Model(self._van_genuchten_model)

        if df is not None:
            self.depth_col = depth_col or 'depth_cm'
            self.load_from_dataframe(df)
        elif filepath:
            # prefer standardized depth header
            self.depth_col = depth_col or 'depth_cm'
            self.load_from_file(filepath)

    def load_from_file(self, filepath):
        """
        Loads SWRC data from a CSV or Parquet file and groups it by depth.
        """
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"File not found at {filepath}")

        if filepath.endswith('.csv'):
            df = pd.read_csv(filepath)
        elif filepath.endswith('.parquet'):
            df = pd.read_parquet(filepath)
        else:
            raise ValueError("File must be a .csv or .parquet file.")

        if 'KPA' in df.columns and 'VWC' in df.columns:
            df['suction'] = np.abs(df['KPA'].values * 10.19716)
            df['theta'] = df['VWC'].values
        elif 'suction_cm' in df.columns and 'theta' in df.columns:
            df['suction'] = np.abs(df['suction_cm'].values)
            df['theta'] = df['theta'].values
        else:
            raise ValueError("Data must contain either ('suction_cm', 'theta') or ('KPA', 'VWC') columns.")

        # Ensure a consistent '_cm' column is available for downstream saving
        if 'suction_cm' not in df.columns:
            df['suction_cm'] = df['suction']

        if self.depth_col in df.columns:
            for depth, group in df.groupby(self.depth_col):
                self.data_by_depth[depth] = group
            # print(f"Data loaded and grouped by {len(self.data_by_depth)} depths.")
        else:
            self.data_by_depth[0] = df
            print("Data loaded as a single dataset (no depth column found).")

    def load_from_dataframe(self, df):
        """
        Load SWRC data from a DataFrame. Accepts columns: ('suction'|'suction_cm'), 'theta', ('depth'|'depth_cm').
        Groups by `self.depth_col` if present; otherwise treats as single dataset.
        """
        cols = set(df.columns)
        has_suction = ('suction' in cols) or ('suction_cm' in cols)
        has_depth = ('depth_cm' in cols) or ('depth' in cols)
        if not has_suction or 'theta' not in cols or not has_depth:
            raise ValueError(
                f"DataFrame missing required columns: need ('suction'|'suction_cm'), 'theta', ('depth'|'depth_cm')")

        # Normalize inputs: create internal 'suction' if only 'suction_cm' provided
        if 'suction' not in df.columns and 'suction_cm' in df.columns:
            df['suction'] = np.abs(df['suction_cm'].values)
        # Choose grouping column preferring explicit centimeters
        group_col = 'depth_cm' if 'depth_cm' in df.columns else 'depth'
        self.depth_col = group_col

        meta_cols = [c for c in df.columns if c not in {'suction_cm', 'theta', group_col}]
        meta_series = df[meta_cols + [group_col]].groupby(group_col).first()
        meta_series = meta_series.to_dict(orient='index')
        self.metadata = meta_series

        if 'suction' in df.columns:
            df['suction'] = np.abs(df['suction'].values)

        if group_col in df.columns:
            for key, group in df.groupby(group_col):
                self.data_by_depth[key] = group
            # print(f"DataFrame loaded and grouped by {self.depth_col} ({len(self.data_by_depth)} groups).")
        else:
            self.data_by_depth[0] = df
            print("DataFrame loaded as a single dataset (no grouping column found).")

    @staticmethod
    def _van_genuchten_model(psi, theta_r, theta_s, alpha, n):
        if n <= 1:
            return np.full_like(psi, np.nan)
        m = 1 - 1 / n
        psi_safe = np.maximum(psi, 1e-9)
        term = 1 + (alpha * psi_safe) ** n
        return theta_r + (theta_s - theta_r) / (term) ** m

    def _generate_initial_params(self, data_for_depth):
        params = self._vg_model.make_params()
        theta_s_init = np.max(data_for_depth['theta'])
        theta_r_init = np.min(data_for_depth['theta'])
        alpha_init = 0.05
        n_init = 1.5
        params['theta_s'].set(value=theta_s_init, min=theta_s_init * 0.9, max=theta_s_init * 1.1)
        params['theta_r'].set(value=theta_r_init, min=0.0, max=theta_r_init * 1.1)
        params['alpha'].set(value=alpha_init, min=1e-5, max=5.0)
        params['n'].set(value=n_init, min=1.001, max=10.0)
        return params

    def fit(self, report=False, method='nelder-meade'):
        """
        Fits the van Genuchten model to the SWRC data for each depth.

        Args:
            report (bool): If True, prints the detailed fit report for each depth.

        Returns:
            dict: A dictionary of lmfit.model.ModelResult objects, keyed by depth.
            :param report:
            :param method:
        """
        # special Bayesian pathway
        if str(method).lower() in {'bayes', 'fit_bayes', 'bayesian'}:
            return self.fit_bayesian()

        self.fit_results = {}
        for depth, data_df in self.data_by_depth.items():
            print(f"--- Fitting for Depth: {depth} cm ---")
            print(f"--- {len(data_df)} data points ---")
            initial_params = self._generate_initial_params(data_df)
            print(f'--- Initial Parameter Values ---')
            [print(f'{k}: {v.value:.3f}') for k, v in initial_params.items()]
            try:
                result = self._vg_model.fit(
                    data_df['theta'], initial_params, psi=data_df['suction'],
                    method=method, nan_policy='raise'  # likely error: lmfit uses 'nelder' not 'nelder-meade'
                )
                self.fit_results[depth] = result
                if report:
                    print(result.fit_report())
            except Exception as e:
                print(f"An error occurred during fitting for depth {depth} cm: {e}")
                self.fit_results[depth] = None
        print("\nAll fits complete.")
        return self.fit_results

    def fit_bayesian(self, draws=2000, tune=1000, target_accept=0.9, chains=4, cores=4, random_seed=None):
        self.bayes_results = {}
        for depth, data_df in self.data_by_depth.items():
            d = data_df.dropna(subset=['suction', 'theta'])
            if len(d) < 4:
                self.bayes_results[depth] = None
                continue
            psi = d['suction'].astype(float).values
            theta = d['theta'].astype(float).values
            with pm.Model() as model:
                theta_r = pm.Beta('theta_r', alpha=1.5, beta=8.0)
                delta = pm.Beta('delta', alpha=2.0, beta=2.0)
                theta_s = pm.Deterministic('theta_s', theta_r + delta * (1.0 - theta_r))
                log_alpha = pm.Normal('log_alpha', mu=np.log(0.05), sigma=1.0)
                alpha = pm.Deterministic('alpha', pt.exp(log_alpha))
                n_minus1 = pm.HalfNormal('n_minus1', sigma=0.75)
                n = pm.Deterministic('n', 1.0 + n_minus1)
                m = 1.0 - 1.0 / n
                psi_safe = pt.maximum(psi, 1e-9)
                term = 1.0 + (alpha * psi_safe) ** n
                mu_theta = theta_r + (theta_s - theta_r) / (term ** m)
                sigma = pm.HalfNormal('sigma', sigma=0.05)
                pm.Normal('obs', mu=mu_theta, sigma=sigma, observed=theta)
                trace = pm.sample(
                    draws=draws, tune=tune, chains=chains, cores=cores,
                    target_accept=target_accept, random_seed=random_seed,
                    progressbar=False, return_inferencedata=True
                )
            self.bayes_results[depth] = trace

        return self.bayes_results

    def test_fit_methods(self, methods_to_test, depth=None):
        """
        Tests multiple fitting algorithms and returns a summary DataFrame.

        Args:
            methods_to_test (list): A list of strings with the names of the
                                    fitting methods to test.
            depth (any, optional): The specific depth to test. If None, the first
                                   available depth is used.

        Returns:
            pandas.DataFrame: A DataFrame summarizing the results, sorted by AIC.
        """
        if not self.data_by_depth:
            print("No data loaded.")
            return

        if depth is None:
            depth = next(iter(self.data_by_depth))

        data_df = self.data_by_depth.get(depth)
        if data_df is None:
            print(f"Depth {depth} not found in data.")
            return

        print(f"--- Testing Fit Methods for Depth: {depth} cm ---")

        # Clean data once
        data_df = data_df.dropna(subset=['suction', 'theta'])
        data_df = data_df[np.isfinite(data_df['suction']) & np.isfinite(data_df['theta'])]

        initial_params = self._generate_initial_params(data_df)
        results_list = []

        for method in methods_to_test:
            print(f"\n--- Testing method: {method} ---")
            start_time = time.time()
            try:
                result = self._vg_model.fit(data_df['theta'], initial_params,
                                            psi=data_df['suction'],
                                            method=method, nan_policy='raise')

                duration = time.time() - start_time
                if result.success:
                    summary = {'method': method, 'success': True, 'AIC': result.aic, 'BIC': result.bic,
                               'time (s)': duration}
                    for param_name, param_obj in result.params.items():
                        summary[f'{param_name}'] = param_obj.value
                        summary[f'{param_name}_stderr'] = param_obj.stderr
                    results_list.append(summary)
                else:
                    results_list.append(
                        {'method': method, 'success': False, 'AIC': np.inf, 'BIC': np.inf, 'time (s)': duration})

            except Exception as e:
                duration = time.time() - start_time
                print(f"Method '{method}' failed with an error: {e}")
                results_list.append(
                    {'method': method, 'success': False, 'AIC': np.inf, 'BIC': np.inf, 'time (s)': duration})

        if not results_list:
            print("No methods completed successfully.")
            return pd.DataFrame()

        results_df = pd.DataFrame(results_list)
        results_df = results_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)

        param_names = ['theta_r', 'theta_s', 'alpha', 'n']

        rel_err_series = []
        for p in param_names:
            val_col = f'{p}'
            err_col = f'{p}_stderr'
            if val_col in results_df.columns and err_col in results_df.columns:
                rel_err = (results_df[err_col] / np.abs(results_df[val_col])) * 100
                rel_err_series.append(rel_err)

        if rel_err_series:
            avg_rel_err = pd.concat(rel_err_series, axis=1).mean(axis=1)
            results_df['avg_rel_err (%)'] = avg_rel_err

        return results_df

    def plot(self, save_path=None, show=True, colormap='plasma'):
        """
        Plots the raw SWRC data and the fitted van Genuchten curve for all depths.
        """
        if not self.fit_results:
            print("Fit has not been performed yet. Please run .fit() first.")
            return

        plt.style.use('seaborn-v0_8-darkgrid')

        # Get the correct colors from the style to apply them explicitly
        facecolor = plt.rcParams['figure.facecolor']
        axescolor = plt.rcParams['axes.facecolor']

        fig, ax = plt.subplots(figsize=(8, 7))

        # Force the background colors to override IDE defaults
        fig.patch.set_facecolor(facecolor)
        ax.set_facecolor(axescolor)

        colors = plt.cm.get_cmap(colormap)(np.linspace(0, 0.85, len(self.data_by_depth)))

        for i, (depth, data_df) in enumerate(self.data_by_depth.items()):
            color = colors[i]
            label_prefix = f'Depth {depth} cm' if self.depth_col in data_df.columns else 'Data'

            ax.plot(data_df['theta'], data_df['suction'], 'o', color=color, label=label_prefix)

            fit_result = self.fit_results.get(depth)
            if fit_result and fit_result.success:
                psi_smooth = np.logspace(np.log10(max(1e-2, data_df['suction'].min())),
                                         np.log10(data_df['suction'].max()), 200)
                theta_fit = fit_result.eval(psi=psi_smooth)
                ax.plot(theta_fit, psi_smooth, '-', color=color)

        ax.set_yscale('log')
        ax.set_ylabel('Soil Water Potential (cm) - Log Scale', fontsize=12)
        ax.set_xlabel('Volumetric Water Content ($cm^3/cm^3$)', fontsize=12)

        title = "Soil Water Retention Curves"
        subtitle = ""
        first_depth_key = next(iter(self.data_by_depth))
        data_df = self.data_by_depth[first_depth_key]
        if 'name' in data_df.columns and data_df['name'].iloc[0] is not None:
            station_name = data_df['name'].iloc[0]
            subtitle = f"({station_name})"
        elif self.filepath:
            subtitle = f"({os.path.basename(self.filepath).replace('.parquet', '')})"

        if subtitle:
            title += f"\n{subtitle}"

        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.legend(fontsize=11)
        ax.grid(True, which="both", ls="--", c='0.7')

        ax.set_xlim(right=0.65)
        ax.set_ylim(top=10 ** 7)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, facecolor=fig.get_facecolor())
            print(f"Plot saved to {save_path}")
        if show:
            plt.show()

    @property
    def results_summary(self):
        """
        Returns a dictionary containing the key results of the fit for each depth.
        Also stores raw data points for plotting (suction [cm], theta) and optional metadata.
        """
        if not self.fit_results:
            return {"status": "Fit not performed."}

        summary = {}
        for depth, result in self.fit_results.items():
            n_obs = len(self.data_by_depth[depth])
            # Prepare raw data snapshot for plotting
            df_raw = self.data_by_depth[depth]
            df_raw = df_raw.dropna(subset=['suction', 'theta'])
            df_raw = df_raw[np.isfinite(df_raw['suction']) & np.isfinite(df_raw['theta'])]
            data_blob = {
                'suction_cm': df_raw['suction'].astype(float).tolist(),
                'theta': df_raw['theta'].astype(float).tolist(),
            }
            if result and result.success:
                params = {}
                for name, param in result.params.items():
                    params[name] = {'value': param.value, 'stderr': param.stderr}
                summary[depth] = {
                    'status': 'Success',
                    'n_obs': n_obs,
                    'chi_squared': result.chisqr,
                    'reduced_chi_squared': result.redchi,
                    'aic': result.aic,
                    'bic': result.bic,
                    'parameters': params,
                    'data': data_blob,
                }
            else:
                summary[depth] = {
                    'status': 'Fit Failed or Not Performed',
                    'n_obs': n_obs,
                    'data': data_blob,
                }
        if self.metadata:
            summary['metadata'] = self.metadata.copy()

        return summary

    def save_results(self, output_dir, output_filename=None, add_data=None):
        """
        Saves the fit results summary to a JSON file.

        Args:
            output_dir (str): The directory to save the results file in.
            output_filename (str, optional): Output filename. If None, derives from input file
                                             name when available, else uses 'swrc_fit_results.json'.
        """
        if not self.fit_results:
            print("Fit has not been performed yet. Cannot save results.")
            return

        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"Created output directory: {output_dir}")

        if output_filename is None:
            if self.filepath:
                base_name = os.path.basename(self.filepath)
                file_name_without_ext = os.path.splitext(base_name)[0]
                output_filename = f"{file_name_without_ext}_fit_results.json"
            else:
                output_filename = "swrc_fit_results.json"
        output_path = os.path.join(output_dir, output_filename)

        summary_data = self.results_summary

        if add_data:
            [summary_data[k].update(v) for k, v in add_data.items()]

        with open(output_path, 'w') as f:
            json.dump(summary_data, f, indent=4)

        print(f"Successfully saved fit results to {output_path}")


    # moved: test_fit_methods_across_stations now in viz/fitting_comparisons/project_fits.py

    def save_bayes_results(self, output_dir, output_filename=None):
        if not hasattr(self, 'bayes_results') or not self.bayes_results:
            return
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        if output_filename is None:
            if self.filepath:
                base_name = os.path.basename(self.filepath)
                file_name_without_ext = os.path.splitext(base_name)[0]
                output_filename = f"{file_name_without_ext}_bayes_results.json"
            else:
                output_filename = "swrc_bayes_results.json"
        output_path = os.path.join(output_dir, output_filename)

        summary = {}
        for depth, trace in self.bayes_results.items():
            if trace is None:
                summary[depth] = {'status': 'Fit Failed or Not Performed'}
                continue
            params = {}
            for name in ['theta_r', 'theta_s', 'alpha', 'n']:
                if hasattr(trace.posterior, name):
                    arr = getattr(trace.posterior, name).values.reshape(-1)
                    mean_ = float(np.mean(arr))
                    params[name] = {
                        'value': mean_,  # align with downstream readers
                        'q025': float(np.quantile(arr, 0.025)),
                        'q975': float(np.quantile(arr, 0.975)),
                    }
            df_raw = self.data_by_depth.get(depth)
            if df_raw is not None:
                d = df_raw.dropna(subset=['suction', 'theta'])
                d = d[np.isfinite(d['suction']) & np.isfinite(d['theta'])]
                data_blob = {
                    'suction_cm': d['suction'].astype(float).tolist(),
                    'theta': d['theta'].astype(float).tolist(),
                }
                n_obs = int(len(d))
            else:
                data_blob = None
                n_obs = 0
            summary[depth] = {
                'status': 'Success',
                'n_obs': n_obs,
                'parameters': params,
                'data': data_blob,
            }

        if self.metadata:
            summary['metadata'] = self.metadata.copy()

        with open(output_path, 'w') as f:
            json.dump(summary, f, indent=4)


if __name__ == '__main__':
    pass
# ========================= EOF ====================================================================
